{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e58db77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9623355263157894\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96      3055\n",
      "           1       0.96      0.97      0.96      3025\n",
      "\n",
      "    accuracy                           0.96      6080\n",
      "   macro avg       0.96      0.96      0.96      6080\n",
      "weighted avg       0.96      0.96      0.96      6080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load train dataset\n",
    "train_dataset = pd.read_csv('train_dataset.csv')\n",
    "\n",
    "# Load test dataset\n",
    "test_dataset = pd.read_csv('test_dataset.csv')\n",
    "\n",
    "# TF-IDF vectorization for text data\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X_train_tfidf = vectorizer.fit_transform(train_dataset['headline'])\n",
    "X_test_tfidf = vectorizer.transform(test_dataset['headline'])\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_tfidf, train_dataset['clickbait'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the classification model\n",
    "classification_model = RandomForestClassifier(random_state=42)\n",
    "classification_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "val_predictions = classification_model.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_val, val_predictions)\n",
    "report = classification_report(y_val, val_predictions)\n",
    "\n",
    "# Print evaluation results\n",
    "print(f\"Validation Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions = classification_model.predict(X_test_tfidf)\n",
    "\n",
    "# Prepare submission file\n",
    "submission_df = pd.DataFrame({'ID': test_dataset['ID'], 'clickbait': test_predictions})\n",
    "submission_df.to_csv('submission222.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a82c80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing DataScience libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm,skew\n",
    "from scipy import stats\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import LinearRegression,Ridge,RidgeCV, ElasticNetCV, LassoCV,BayesianRidge\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler,StandardScaler,MinMaxScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split, GridSearchCV\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score,mean_absolute_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c395ae52",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RandomForestClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 11\u001b[0m\n\u001b[1;32m      4\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m300\u001b[39m],\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m30\u001b[39m],\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# Add other parameters to tune\u001b[39;00m\n\u001b[1;32m      8\u001b[0m }\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Perform Grid Search\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(\u001b[43mRandomForestClassifier\u001b[49m(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m), param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     12\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mfit(X_train_tfidf, y_train)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Check the best parameters\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RandomForestClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid for RandomForestClassifier\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    # Add other parameters to tune\n",
    "}\n",
    "\n",
    "# Perform Grid Search\n",
    "grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5)\n",
    "grid_search.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Check the best parameters\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Get the best model\n",
    "best_rf_model = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40093660",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load train_dataset.csv and test_dataset.csv\n",
    "train_dataset = pd.read_csv('train_dataset.csv')\n",
    "test_dataset = pd.read_csv('test_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba6e0ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>clickbait</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hussein enters \"not guilty\" plea at trial</td>\n",
       "      <td>0</td>\n",
       "      <td>84698cc7-8ae2-4ea3-a425-b7091561cee6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iraq peace talks draw to a close in Finland</td>\n",
       "      <td>0</td>\n",
       "      <td>a4e35ca4-15fa-43e8-b68e-91457b23afee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>British Premier Visits Northern Ireland</td>\n",
       "      <td>0</td>\n",
       "      <td>162991ee-ea2f-41ad-a753-649a68f54311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Decline of Left-Handed First Basemen</td>\n",
       "      <td>0</td>\n",
       "      <td>2cd3aa32-6ec2-4af1-bd1d-560709066b8b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Who Said It: Donald Trump Or Kanye West</td>\n",
       "      <td>1</td>\n",
       "      <td>72553370-c348-4603-882b-39e04b610c39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      headline  clickbait  \\\n",
       "0    Hussein enters \"not guilty\" plea at trial          0   \n",
       "1  Iraq peace talks draw to a close in Finland          0   \n",
       "2      British Premier Visits Northern Ireland          0   \n",
       "3     The Decline of Left-Handed First Basemen          0   \n",
       "4      Who Said It: Donald Trump Or Kanye West          1   \n",
       "\n",
       "                                     ID  \n",
       "0  84698cc7-8ae2-4ea3-a425-b7091561cee6  \n",
       "1  a4e35ca4-15fa-43e8-b68e-91457b23afee  \n",
       "2  162991ee-ea2f-41ad-a753-649a68f54311  \n",
       "3  2cd3aa32-6ec2-4af1-bd1d-560709066b8b  \n",
       "4  72553370-c348-4603-882b-39e04b610c39  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9da589aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5f99b099-c4db-4a02-9753-28c5e94a6b34</td>\n",
       "      <td>Israeli military launches airstrikes into Gaza...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3c413552-32c0-4000-a745-b4217fe427ca</td>\n",
       "      <td>Expelled' fair use upheld</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71060e3b-bab0-4218-b1ce-8284ae46f6c3</td>\n",
       "      <td>31 Times Frankie Boyle's Twitter Was Out Of Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f0a03121-600f-4b69-b6db-989d0f3cf28a</td>\n",
       "      <td>What Does Your Zodiac Sign Say About Your Love...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>456f7cfa-bdfe-45bd-9e88-7c4ae53eb4ba</td>\n",
       "      <td>Larson B ice-shelf collapse reveals exotic org...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     ID  \\\n",
       "0  5f99b099-c4db-4a02-9753-28c5e94a6b34   \n",
       "1  3c413552-32c0-4000-a745-b4217fe427ca   \n",
       "2  71060e3b-bab0-4218-b1ce-8284ae46f6c3   \n",
       "3  f0a03121-600f-4b69-b6db-989d0f3cf28a   \n",
       "4  456f7cfa-bdfe-45bd-9e88-7c4ae53eb4ba   \n",
       "\n",
       "                                            headline  \n",
       "0  Israeli military launches airstrikes into Gaza...  \n",
       "1                          Expelled' fair use upheld  \n",
       "2  31 Times Frankie Boyle's Twitter Was Out Of Co...  \n",
       "3  What Does Your Zodiac Sign Say About Your Love...  \n",
       "4  Larson B ice-shelf collapse reveals exotic org...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43dadb87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30400, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# The rows and columns of our dataset \n",
    "train_dataset.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78245683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['headline', 'clickbait', 'ID'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Well we have to deal with plenty of attributes \n",
    "train_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36a1023e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID          object\n",
       "headline    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Datatype of each attribute\n",
    "test_dataset.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003fa089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive Statistics of Numerical Variables\n",
    "train_dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c68976",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Statistics of our Categorical variables\n",
    "train_dataset.describe(include=['O'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d066784e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for the Missing values\n",
    "# Using isnull fuction to count the total null values in each field\n",
    "total = train_dataset.isnull().sum().sort_values(ascending=False) \n",
    "# Percent of missing values is estimated by dividing total missing and the original total\n",
    "percent = (train_dataset.isnull().sum()/train_dataset.isnull().count()).sort_values(ascending=False)\n",
    "# Concatenating the Total and Percent fields sing pandas concat fucntion\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "# Displays top 20 from our max sorted list\n",
    "missing_data.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ea1483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Well! Things look better now! \n",
    "train_dataset.isnull().sum().max()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af59373b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import nltk\n",
    "import sklearn\n",
    "import pandas\n",
    "import numpy\n",
    "\n",
    "print('Python: {}'.format(sys.version))\n",
    "print('NLTK: {}'.format(nltk.__version__))\n",
    "print('Scikit-learn: {}'.format(sklearn.__version__))\n",
    "print('Pandas: {}'.format(pandas.__version__))\n",
    "print('Numpy: {}'.format(numpy.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518f025d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier  # Import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_dataset['headline'], train_dataset['clickbait'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert text data to numerical features using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize and train the classification model\n",
    "classification_model = RandomForestClassifier(random_state=42)\n",
    "classification_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = classification_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the classification model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf79fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test dataset (assuming 'test_data.csv' as the file name)\n",
    "test_dataset = pd.read_csv('test_dataset.csv')\n",
    "\n",
    "# Preprocess the test data\n",
    "X_test_tfidf = vectorizer.transform(test_dataset['headline'])\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions = classification_model.predict_proba(X_test_tfidf)[:, 1]  # Probability of being clickbait\n",
    "\n",
    "# Assuming you have already obtained test_predictions from your model\n",
    "\n",
    "threshold = 0.5  # Set your threshold value here\n",
    "\n",
    "# Convert probabilities to binary predictions based on the threshold\n",
    "binary_predictions = [1 if prob >= threshold else 0 for prob in test_predictions]\n",
    "\n",
    "# Create a DataFrame with ID and predicted probabilities\n",
    "submission_df = pd.DataFrame({'ID': test_dataset['ID'], 'clickbait': binary_predictions})\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "submission_df.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55020bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05fd39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# We can use sklearn algorithms in NLTK\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SklearnClassifier(SVC(kernel = 'linear'))\n",
    "\n",
    "# train the model on the training data\n",
    "model.clickbait(training)\n",
    "\n",
    "# and test on the testing dataset!\n",
    "accuracy = nltk.classify.accuracy(model, testing)*100\n",
    "print(\"SVC Accuracy: {}\".format(accuracy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a8a47d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca876b3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13fd09b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f600a46b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02bce13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fba4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Python: 3.10.6 (main, Mar 10 2023, 10:55:28) [GCC 11.3.0]\n",
    "NLTK: 3.8.1\n",
    "Scikit-learn: 1.3.0\n",
    "Pandas: 1.5.3\n",
    "Numpy: 1.21.5\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier  # Import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "​\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_dataset['headline'], train_dataset['clickbait'], test_size=0.2, random_state=50)\n",
    "\n",
    "​\n",
    "\n",
    "# Convert text data to numerical features using TF-IDF\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "​\n",
    "\n",
    "# Initialize and train the classification model\n",
    "\n",
    "classification_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "classification_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "​\n",
    "\n",
    "# Make predictions on the test set\n",
    "\n",
    "y_pred = classification_model.predict(X_test_tfidf)\n",
    "\n",
    "​\n",
    "\n",
    "# Evaluate the classification model\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "​\n",
    "\n",
    "# Print the evaluation results\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "​\n",
    "\n",
    "Accuracy: 0.9629934210526315\n",
    "Classification Report:\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "           0       0.97      0.96      0.96      3046\n",
    "           1       0.96      0.97      0.96      3034\n",
    "\n",
    "    accuracy                           0.96      6080\n",
    "   macro avg       0.96      0.96      0.96      6080\n",
    "weighted avg       0.96      0.96      0.96      6080\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eef9faf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6321fe2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42366c17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27a4955",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
